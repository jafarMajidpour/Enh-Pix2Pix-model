{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91370850-754b-4d40-9dff-8c2087f02d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ ======================================================================\n",
      "üöÄ PIX2PIX IMAGE GENERATOR\n",
      "üöÄ ======================================================================\n",
      "\n",
      "üìã CURRENT CONFIGURATION:\n",
      "   üéØ Model: G:/Sparse2/Results/Chest/10/checkpoints/best_model.pth\n",
      "   üì∏ Input: G:/Sparse2/Results/Chest/10/checkpoints/1/LIDC-IDRI-0004_1-001.png\n",
      "   üíæ Output: G:/Sparse2/Results/Chest/10/checkpoints/1/LIDC-IDRI-0004_1-001.png\n",
      "   üñ•Ô∏è Device: auto\n",
      "   üìè Image Size: 256x256\n",
      "\n",
      "üéÆ AVAILABLE MODES:\n",
      "   1. Single Image Generation\n",
      "   2. Batch Processing\n",
      "   3. Interactive Mode\n",
      "\n",
      "\n",
      "==================================================\n",
      "üéØ Choose a mode:\n",
      "1. Generate single image (using config above)\n",
      "2. Batch process folder\n",
      "3. Interactive mode\n",
      "4. Exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your choice (1-4):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® ============================================================\n",
      "üé® PIX2PIX IMAGE GENERATOR - SINGLE IMAGE\n",
      "üé® ============================================================\n",
      "üíª Using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shorsh\\AppData\\Local\\Temp\\ipykernel_10472\\4006084283.py:148: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Model loaded successfully!\n",
      "üèÜ Best validation PSNR: 22.54 dB\n",
      "‚úÖ Pix2Pix Generator ready!\n",
      "üéÆ Device: cpu\n",
      "üìÅ Model: G:/Sparse2/Results/Chest/10/checkpoints/best_model.pth\n",
      "\n",
      "üñºÔ∏è Processing: G:/Sparse2/Results/Chest/10/checkpoints/1/LIDC-IDRI-0004_1-001.png\n",
      "‚úÖ Generated image saved: G:/Sparse2/Results/Chest/10/checkpoints/1/LIDC-IDRI-0004_1-001.png\n",
      "üìä Comparison saved: G:/Sparse2/Results/Chest/10/checkpoints/1/LIDC-IDRI-0004_1-001_comparison.png\n",
      "\n",
      "üéâ SUCCESS!\n",
      "üì∏ Input: G:/Sparse2/Results/Chest/10/checkpoints/1/LIDC-IDRI-0004_1-001.png\n",
      "üé® Output: G:/Sparse2/Results/Chest/10/checkpoints/1/LIDC-IDRI-0004_1-001.png\n",
      "üìä Comparison: G:/Sparse2/Results/Chest/10/checkpoints/1/LIDC-IDRI-0004_1-001_comparison.png\n",
      "\n",
      "==================================================\n",
      "üéØ Choose a mode:\n",
      "1. Generate single image (using config above)\n",
      "2. Batch process folder\n",
      "3. Interactive mode\n",
      "4. Exit\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "MODEL_PATH = \"G:/Sparse2/Results/Chest/10/checkpoints/best_model.pth\"  # Path to your best_model.pth\n",
    "INPUT_IMAGE_PATH = \"G:/Sparse2/Results/Chest/10/checkpoints/1/LIDC-IDRI-0004_1-001.png\"  # Input image to process\n",
    "OUTPUT_PATH = \"G:/Sparse2/Results/Chest/10/checkpoints/1/LIDC-IDRI-0004_1-001.png\"  # Where to save result\n",
    "\n",
    "# Model configuration (should match training config)\n",
    "IMAGE_SIZE = 256\n",
    "DEVICE = 'auto'  # 'auto', 'cuda', or 'cpu'\n",
    "\n",
    "class EnhancedGenerator(nn.Module):\n",
    "    \"\"\"Enhanced U-Net Generator - Same as training version\"\"\"\n",
    "    \n",
    "    def __init__(self, input_nc=3, output_nc=3, ngf=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder layers\n",
    "        self.e1 = self._make_layer(input_nc, ngf, normalize=False)\n",
    "        self.e2 = self._make_layer(ngf, ngf * 2)\n",
    "        self.e3 = self._make_layer(ngf * 2, ngf * 4)\n",
    "        self.e4 = self._make_layer(ngf * 4, ngf * 8)\n",
    "        self.e5 = self._make_layer(ngf * 8, ngf * 8)\n",
    "        self.e6 = self._make_layer(ngf * 8, ngf * 8)\n",
    "        self.e7 = self._make_layer(ngf * 8, ngf * 8)\n",
    "        self.e8 = self._make_layer(ngf * 8, ngf * 8, normalize=False)\n",
    "        \n",
    "        # Decoder layers\n",
    "        self.d1 = self._make_up_layer(ngf * 8, ngf * 8, dropout=True)\n",
    "        self.d2 = self._make_up_layer(ngf * 16, ngf * 8, dropout=True)\n",
    "        self.d3 = self._make_up_layer(ngf * 16, ngf * 8, dropout=True)\n",
    "        self.d4 = self._make_up_layer(ngf * 16, ngf * 8)\n",
    "        self.d5 = self._make_up_layer(ngf * 16, ngf * 4)\n",
    "        self.d6 = self._make_up_layer(ngf * 8, ngf * 2)\n",
    "        self.d7 = self._make_up_layer(ngf * 4, ngf)\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.ConvTranspose2d(ngf * 2, output_nc, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def _make_layer(self, in_channels, out_channels, normalize=True):\n",
    "        layers = [nn.Conv2d(in_channels, out_channels, 4, 2, 1)]\n",
    "        if normalize:\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "        layers.append(nn.LeakyReLU(0.2, True))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _make_up_layer(self, in_channels, out_channels, dropout=False):\n",
    "        layers = [\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(True)\n",
    "        ]\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout2d(0.5))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.e1(x)\n",
    "        e2 = self.e2(e1)\n",
    "        e3 = self.e3(e2)\n",
    "        e4 = self.e4(e3)\n",
    "        e5 = self.e5(e4)\n",
    "        e6 = self.e6(e5)\n",
    "        e7 = self.e7(e6)\n",
    "        e8 = self.e8(e7)\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        d1 = self.d1(e8)\n",
    "        d2 = self.d2(torch.cat([d1, e7], 1))\n",
    "        d3 = self.d3(torch.cat([d2, e6], 1))\n",
    "        d4 = self.d4(torch.cat([d3, e5], 1))\n",
    "        d5 = self.d5(torch.cat([d4, e4], 1))\n",
    "        d6 = self.d6(torch.cat([d5, e3], 1))\n",
    "        d7 = self.d7(torch.cat([d6, e2], 1))\n",
    "        \n",
    "        output = self.final(torch.cat([d7, e1], 1))\n",
    "        return output\n",
    "\n",
    "class Pix2PixGenerator: # IMAGE GENERATOR CLASS\n",
    "    \"\"\"Simple interface for generating images with trained Pix2Pix model\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path, device='auto'):\n",
    "        self.device = self._setup_device(device)\n",
    "        self.model = self._load_model(model_path)\n",
    "        self.transform = self._setup_transforms()\n",
    "        \n",
    "        print(f\" Pix2Pix Generator ready!\")\n",
    "        print(f\" Device: {self.device}\")\n",
    "        print(f\" Model: {model_path}\")\n",
    "    \n",
    "    def _setup_device(self, device):\n",
    "        \"\"\"Setup computation device\"\"\"\n",
    "        if device == 'auto':\n",
    "            if torch.cuda.is_available():\n",
    "                device = 'cuda'\n",
    "                print(f\" Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "            else:\n",
    "                device = 'cpu'\n",
    "                print(\" Using CPU\")\n",
    "        \n",
    "        try:\n",
    "            # Test device\n",
    "            test_tensor = torch.randn(1, 3, 64, 64).to(device)\n",
    "            return device\n",
    "        except Exception as e:\n",
    "            print(f\" Device '{device}' failed, using CPU: {e}\")\n",
    "            return 'cpu'\n",
    "    \n",
    "    def _load_model(self, model_path):\n",
    "        \"\"\"Load the trained generator model\"\"\"\n",
    "        try:\n",
    "            # Load checkpoint\n",
    "            checkpoint = torch.load(model_path, map_location=self.device)\n",
    "            \n",
    "            # Create generator\n",
    "            generator = EnhancedGenerator(input_nc=3, output_nc=3, ngf=64)\n",
    "            generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "            generator.to(self.device)\n",
    "            generator.eval()\n",
    "            \n",
    "            print(f\" Model loaded successfully!\")\n",
    "            if 'best_val_psnr' in checkpoint:\n",
    "                print(f\" Best validation PSNR: {checkpoint['best_val_psnr']:.2f} dB\")\n",
    "            \n",
    "            return generator\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" Error loading model: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _setup_transforms(self):\n",
    "        \"\"\"Setup image preprocessing transforms\"\"\"\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((IMAGE_SIZE, IMAGE_SIZE), Image.LANCZOS),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x * 2.0 - 1.0)  # Normalize to [-1, 1]\n",
    "        ])\n",
    "    \n",
    "    def generate_image(self, input_path, output_path, save_comparison=True):\n",
    "        \"\"\"\n",
    "        Generate image from input\n",
    "        \n",
    "        Args:\n",
    "            input_path: Path to input image\n",
    "            output_path: Path to save generated image\n",
    "            save_comparison: Whether to save side-by-side comparison\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(f\"\\nüñºÔ∏è Processing: {input_path}\")\n",
    "            \n",
    "            # Load and preprocess input image\n",
    "            input_img = Image.open(input_path).convert('RGB')\n",
    "            original_size = input_img.size\n",
    "            \n",
    "            # Transform for model\n",
    "            input_tensor = self.transform(input_img).unsqueeze(0).to(self.device)\n",
    "            \n",
    "            # Generate image\n",
    "            with torch.no_grad():\n",
    "                generated_tensor = self.model(input_tensor)\n",
    "            \n",
    "            # Convert back to PIL image\n",
    "            generated_img = self._tensor_to_pil(generated_tensor.squeeze(0))\n",
    "            \n",
    "            # Resize back to original size if needed\n",
    "            if original_size != (IMAGE_SIZE, IMAGE_SIZE):\n",
    "                generated_img = generated_img.resize(original_size, Image.LANCZOS)\n",
    "                input_img = input_img.resize(original_size, Image.LANCZOS)\n",
    "            \n",
    "            # Save generated image\n",
    "            generated_img.save(output_path)\n",
    "            print(f\"‚úÖ Generated image saved: {output_path}\")\n",
    "            \n",
    "            # Save comparison if requested\n",
    "            if save_comparison:\n",
    "                comparison_path = output_path.replace('.', '_comparison.')\n",
    "                self._save_comparison(input_img, generated_img, comparison_path)\n",
    "                print(f\"üìä Comparison saved: {comparison_path}\")\n",
    "            \n",
    "            return generated_img\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error generating image: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _tensor_to_pil(self, tensor):\n",
    "        \"\"\"Convert tensor to PIL image\"\"\"\n",
    "        # Denormalize from [-1, 1] to [0, 1]\n",
    "        tensor = (tensor + 1) / 2\n",
    "        tensor = torch.clamp(tensor, 0, 1)\n",
    "        \n",
    "        # Convert to PIL\n",
    "        return transforms.ToPILImage()(tensor)\n",
    "    \n",
    "    def _save_comparison(self, input_img, generated_img, output_path):\n",
    "        \"\"\"Save side-by-side comparison\"\"\"\n",
    "        # Create comparison image\n",
    "        width, height = input_img.size\n",
    "        comparison = Image.new('RGB', (width * 2, height), (255, 255, 255))\n",
    "        \n",
    "        # Paste images\n",
    "        comparison.paste(input_img, (0, 0))\n",
    "        comparison.paste(generated_img, (width, 0))\n",
    "        \n",
    "        # Save\n",
    "        comparison.save(output_path)\n",
    "    \n",
    "    def generate_batch(self, input_folder, output_folder, file_extensions=None):\n",
    "        \"\"\"\n",
    "        Generate images for all files in a folder\n",
    "        \n",
    "        Args:\n",
    "            input_folder: Folder containing input images\n",
    "            output_folder: Folder to save generated images\n",
    "            file_extensions: List of extensions to process (default: common image types)\n",
    "        \"\"\"\n",
    "        if file_extensions is None:\n",
    "            file_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
    "        \n",
    "        # Create output folder\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "        # Find all image files\n",
    "        image_files = []\n",
    "        for ext in file_extensions:\n",
    "            for file_ext in [ext.lower(), ext.upper()]:\n",
    "                pattern = os.path.join(input_folder, f\"*{file_ext}\")\n",
    "                import glob\n",
    "                image_files.extend(glob.glob(pattern))\n",
    "        \n",
    "        if not image_files:\n",
    "            print(f\"‚ö†Ô∏è No image files found in {input_folder}\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nüìÅ Processing {len(image_files)} images from {input_folder}\")\n",
    "        \n",
    "        # Process each image\n",
    "        for i, input_path in enumerate(image_files, 1):\n",
    "            try:\n",
    "                filename = os.path.basename(input_path)\n",
    "                name, ext = os.path.splitext(filename)\n",
    "                output_path = os.path.join(output_folder, f\"{name}_generated{ext}\")\n",
    "                \n",
    "                print(f\"\\n[{i}/{len(image_files)}] Processing: {filename}\")\n",
    "                self.generate_image(input_path, output_path)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed to process {filename}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"\\nüéâ Batch processing completed!\")\n",
    "        print(f\"üìÅ Results saved to: {output_folder}\")\n",
    "\n",
    "def generate_single_image():   # MAIN EXECUTION FUNCTIONS\n",
    "    \"\"\"Generate a single image\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"PIX2PIX IMAGE GENERATOR - SINGLE IMAGE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Validate paths\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        print(f\" Model not found: {MODEL_PATH}\")\n",
    "        print(\" Please update MODEL_PATH in the script\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(INPUT_IMAGE_PATH):\n",
    "        print(f\" Input image not found: {INPUT_IMAGE_PATH}\")\n",
    "        print(\" Please update INPUT_IMAGE_PATH in the script\")\n",
    "        return\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # Initialize generator\n",
    "        generator = Pix2PixGenerator(MODEL_PATH, DEVICE)\n",
    "        \n",
    "        # Generate image\n",
    "        generated_img = generator.generate_image(INPUT_IMAGE_PATH, OUTPUT_PATH)\n",
    "        \n",
    "        print(f\"\\n SUCCESS!\")\n",
    "        print(f\" Input: {INPUT_IMAGE_PATH}\")\n",
    "        print(f\" Output: {OUTPUT_PATH}\")\n",
    "        print(f\" Comparison: {OUTPUT_PATH.replace('.', '_comparison.')}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Generation failed: {e}\")\n",
    "\n",
    "def generate_batch_images():\n",
    "    \"\"\"Generate images for a folder\"\"\"\n",
    "    print( \"=\"*60)\n",
    "    print(\" PIX2PIX IMAGE GENERATOR - BATCH PROCESSING\")\n",
    "    print( \"=\"*60)\n",
    "    \n",
    "    # Get input folder from input image path\n",
    "    input_folder = os.path.dirname(INPUT_IMAGE_PATH)\n",
    "    output_folder = os.path.join(os.path.dirname(OUTPUT_PATH), \"batch_generated\")\n",
    "    \n",
    "    print(f\" Input folder: {input_folder}\")\n",
    "    print(f\" Output folder: {output_folder}\")\n",
    "    \n",
    "    # Validate paths\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        print(f\" Model not found: {MODEL_PATH}\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(input_folder):\n",
    "        print(f\" Input folder not found: {input_folder}\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Initialize generator\n",
    "        generator = Pix2PixGenerator(MODEL_PATH, DEVICE)\n",
    "        \n",
    "        # Generate batch\n",
    "        generator.generate_batch(input_folder, output_folder)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Batch generation failed: {e}\")\n",
    "\n",
    "def interactive_mode():\n",
    "    \"\"\"Interactive mode for generating images\"\"\"\n",
    "    print( \"=\"*60)\n",
    "    print(\" PIX2PIX GENERATOR - INTERACTIVE MODE\")\n",
    "    print( + \"=\"*60)\n",
    "    \n",
    "    # Validate model\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        print(f\" Model not found: {MODEL_PATH}\")\n",
    "        print(\" Please update MODEL_PATH in the script\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Initialize generator once\n",
    "        generator = Pix2PixGenerator(MODEL_PATH, DEVICE)\n",
    "        \n",
    "        while True:\n",
    "            print(f\"\\n\" + \"=\"*50)\n",
    "            print(\" Choose an option:\")\n",
    "            print(\"1. Generate single image\")\n",
    "            print(\"2. Process folder\")\n",
    "            print(\"3. Exit\")\n",
    "            \n",
    "            choice = input(\"\\nEnter your choice (1-3): \").strip()\n",
    "            \n",
    "            if choice == '1':\n",
    "                input_path = input(\"üì∏ Enter input image path: \").strip()\n",
    "                if not os.path.exists(input_path):\n",
    "                    print(f\" File not found: {input_path}\")\n",
    "                    continue\n",
    "                \n",
    "                output_path = input(\"üíæ Enter output path: \").strip()\n",
    "                os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "                \n",
    "                try:\n",
    "                    generator.generate_image(input_path, output_path)\n",
    "                    print(f\" Generated: {output_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\" Error: {e}\")\n",
    "            \n",
    "            elif choice == '2':\n",
    "                input_folder = input(\"üìÅ Enter input folder path: \").strip()\n",
    "                if not os.path.exists(input_folder):\n",
    "                    print(f\" Folder not found: {input_folder}\")\n",
    "                    continue\n",
    "                \n",
    "                output_folder = input(\" Enter output folder path: \").strip()\n",
    "                \n",
    "                try:\n",
    "                    generator.generate_batch(input_folder, output_folder)\n",
    "                except Exception as e:\n",
    "                    print(f\" Error: {e}\")\n",
    "            \n",
    "            elif choice == '3':\n",
    "                print(\" Goodbye!\")\n",
    "                break\n",
    "            \n",
    "            else:\n",
    "                print(\" Invalid choice. Please enter 1, 2, or 3.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\" Failed to initialize generator: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    print(\"üöÄ \" + \"=\"*70)\n",
    "    print(\"üöÄ PIX2PIX IMAGE GENERATOR\")\n",
    "    print(\"üöÄ \" + \"=\"*70)\n",
    "    \n",
    "    print(f\"\"\"\n",
    " CURRENT CONFIGURATION:\n",
    "    Model: {MODEL_PATH}\n",
    "    Input: {INPUT_IMAGE_PATH}\n",
    "    Output: {OUTPUT_PATH}\n",
    "    Device: {DEVICE}\n",
    "    Image Size: {IMAGE_SIZE}x{IMAGE_SIZE}\n",
    "\n",
    " AVAILABLE MODES:\n",
    "   1. Single Image Generation\n",
    "   2. Batch Processing\n",
    "   3. Interactive Mode\n",
    "\"\"\")\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\" Choose a mode:\")\n",
    "        print(\"1. Generate single image (using config above)\")\n",
    "        print(\"2. Batch process folder\")\n",
    "        print(\"3. Interactive mode\")\n",
    "        print(\"4. Exit\")\n",
    "        \n",
    "        choice = input(\"\\nEnter your choice (1-4): \").strip()\n",
    "        \n",
    "        if choice == '1':\n",
    "            generate_single_image()\n",
    "        elif choice == '2':\n",
    "            generate_batch_images()\n",
    "        elif choice == '3':\n",
    "            interactive_mode()\n",
    "        elif choice == '4':\n",
    "            print(\" Goodbye!\")\n",
    "            break\n",
    "        else:\n",
    "            print(\" Invalid choice. Please enter 1, 2, 3, or 4.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d286dac4-5bfe-4db3-805f-adebfe7943f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
